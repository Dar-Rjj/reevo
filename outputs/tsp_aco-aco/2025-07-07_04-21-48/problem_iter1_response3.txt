```python
import numpy as np

def heuristics_v2(distance_matrix: np.ndarray) -> np.ndarray:
    # Avoid division by zero
    eps = 1e-8
    distance_matrix += eps
    
    # Inverse distance as base heuristic (shorter edges are more promising)
    inv_dist = 1.0 / distance_matrix
    
    # Normalize row-wise to reflect relative attractiveness within each node's connections
    row_sums = inv_dist.sum(axis=1, keepdims=True)
    normalized_inv_dist = inv_dist / row_sums
    
    # Compute average distance for each node to all others (to estimate centrality)
    avg_distances = np.mean(distance_matrix, axis=1, keepdims=True)
    
    # Nodes with higher average distance are more "peripheral", their short edges may be more critical
    centrality_weights = 1.0 / (avg_distances + eps)
    centrality_matrix = normalized_inv_dist * centrality_weights
    
    # Sparsify: set edges below the 75th percentile to zero (discourage long-distance connections)
    threshold = np.percentile(centrality_matrix[np.triu_indices_from(centrality_matrix, k=1)], 75)
    sparse_central_matrix = np.where(centrality_matrix >= threshold, centrality_matrix, 0)
    
    return sparse_central_matrix
```
